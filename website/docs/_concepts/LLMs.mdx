---
sidebar_position: 3
sidebar_label: Large Language Models
---

# Large Language Models (LLMs)
Large Language Models (LLMs) are a class of advanced artificial intelligence systems designed to understand, generate, and reason over natural language at scale.

They are based primarily on deep neural networks (most commonly transformer architectures) and are trained on massive volumes of text data to learn linguistic patterns, semantic relationships, and contextual dependencies. 

LLMs are the evolution of Natural Language Processing and Generative AI into general-purpose language systems capable of performing a wide range of cognitive tasks.

LLMs are distinguished by:
Very large model size (billions to trillions of parameters)
Training on diverse, large-scale text datasets
Ability to perform multiple tasks without reprogramming
Natural languages the primary interface

Putting face to face traditional NLP models and LLMs we see key differences
