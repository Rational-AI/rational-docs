---
sidebar_position: 3
sidebar_label: Governance
---
# Governance

The governance module in Rational AI’s Control Room provides observability and accountability over AI model usage.  It offers dashboards and detailed logs that help administrators track costs, token consumption, inference performance and conversational activity.  This document describes the key features available in the **Dashboard** and **Audit Log** views and explains how to navigate and filter the data.

## Overview

The governance interface is available after signing into the Control Room and selecting **Governance** from the top navigation bar.  Two primary views are provided:

* **Dashboard:**  A high‑level overview of usage metrics and performance for the selected data type (APIs or conversational interactions).
* **Audit Log:**  A detailed table of individual inference or conversation events with sortable columns and flexible filtering options.

Users can switch between these views using the tabs near the top of the page.  The module supports multiple filters—**Type**, **Touchpoints**, **Models** and **Period**—allowing administrators to tailor the data display.

## Dashboard

The dashboard presents aggregated metrics for the selected **Type** (default: *APIs*).  It is organised into two sections: **Overview** and **Details**.

### Type Selector

The **Type** drop‑down at the top of the dashboard determines whether API or conversational data is displayed.  Available options include:

| Type            | Description                                                     |
|-----------------|-----------------------------------------------------------------|
| **APIs**        | Shows metrics for API‑based inference calls.                    |
| **Conversational** | Displays metrics for end‑user conversations with chat agents. |

### Overview Cards

At the top of the dashboard a series of cards summarise key performance indicators:

* **Total costs** – The cumulative cost of API calls or conversations over the selected period.  For API calls this value is shown in euros; if cost tracking is disabled it may read `0,00 €`.
* **Total inferences** – The number of API calls or conversation interactions.
* **Total input tokens** – The total number of tokens sent to models.
* **Total output tokens** – The total number of tokens returned by models.

Each card updates automatically when filters are changed (e.g., selecting a different touchpoint or model).

### Details Section

Below the overview cards, interactive charts provide deeper insights:

* **Total tokens** – A bar/line chart comparing input tokens and output tokens over time.  A legend distinguishes input (e.g., blue) and output (purple) tokens.
* **Tokens per second (avg)** – Shows the average throughput in tokens per second across the selected period.
* **Inferences** – Displays the number of calls or conversation turns over time.
* **Tokens per inference (avg)** – Illustrates the average number of tokens consumed per inference.
* **Costs** – A chart showing total cost over time.  If cost tracking is disabled the values remain zero.
* **Cost per inference (avg)** – Visualises the average cost per call.
* **Time to first token (avg)** – Measures the latency (in seconds) between the request initiation and receipt of the first token.

These charts update dynamically when you adjust filters.  Hovering over a point reveals the underlying data for that date or time bucket.

### Filters

Several filters control what data is shown:

| Filter        | Options & Behaviour                                                                                         |
|---------------|-------------------------------------------------------------------------------------------------------------|
| **Type**      | Allows switching between **APIs** and **Conversational** data.                                              |
| **Touchpoints** | Multi‑select list of registered touchpoints (e.g., *Pengo Products*, *Siena Living – Orders*).  Selecting one or more touchpoints restricts the data to those user flows. |
| **Models**     | Multi‑select list of deployed models (e.g., `qwen/qwen3-30b-a3b-instruct-2507`, `BAAI/bge-m3`).             |
| **Period**     | Predefined ranges: *Last 24 hours*, *Last 7 days*, *Last 30 days* (default), *Last 3 months*, *Last 6 months*. Selecting a period adjusts the time span of all charts and counts. |

Each filter has a drop‑down interface with check boxes for multi‑select options.  Changes are applied immediately, updating both the overview cards and the detailed charts.

## Audit Log

The **Audit Log** tab provides fine‑grained visibility into individual calls or conversation messages.  It features a paginated and horizontally scrollable table with the following columns:

| Column             | Description                                                                                 |
|--------------------|---------------------------------------------------------------------------------------------|
| **Timestamp**      | Date and time when the inference was executed.  Sorting is available by clicking the header. |
| **Model**          | Name of the model used for the inference (e.g., `qwen/qwen3-30b-a3b-instruct-2507`).          |
| **Touchpoint**     | The touchpoint or conversational entry point that triggered the call.                         |
| **Tokens**         | Displays input tokens and output tokens in the form *input → output*.                        |
| **Costs**          | Monetary cost associated with the call.                                                      |
| **TTFT (Time to first token)** | Latency until the first token is received (seconds).                              |
| **E2E latency**    | Total end‑to‑end latency of the call or conversation message (seconds).                      |
| **Speed**          | Throughput of the response measured in tokens per second (tps).                              |
| **Finish**         | Indicates how the call concluded (e.g., `stop`).                                             |

### Filtering in Audit Log

Like the dashboard, the audit log includes filter controls above the table:

* **Type** – Choose between **APIs** and **Conversational**.  This determines whether the table lists API calls or chat messages.
* **Touchpoints** – Multi‑select list of touchpoints.  Selecting one or more limits the events to those sources.
* **Models** – Multi‑select list of models.  This filter is useful for isolating calls to specific models.
* **Period** – Preset time ranges identical to the dashboard (Last 24 hours, Last 7 days, etc.).
